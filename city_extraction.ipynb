{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Dividing data into separate niches and working out means (with corrections) from it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import csv\n",
      "import learn\n",
      "data = pandas.read_csv('/home/mike/dev/311/data/train_reformatted.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Define our cities"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "city_1_boundaries = (37.4,37.7)\n",
      "city_2_boundaries = (37.7,37.9)\n",
      "city_3_boundaries = (41.24,41.3)\n",
      "city_4_boundaries = (41.3,41.4)\n",
      "city_5_boundaries = (41.6,42.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Method to separate them out"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def select(data,city):\n",
      "    \"\"\"\n",
      "    Return a data frame for the city within the correct latitudes\n",
      "    \"\"\"\n",
      "    latitude_min = city[0]\n",
      "    latitude_max = city[1]\n",
      "    selected = data[(data.latitude >= latitude_min) & (data.latitude < latitude_max)]\n",
      "    return selected"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "city_1 = select(data,city_1_boundaries)\n",
      "city_2 = select(data,city_2_boundaries)\n",
      "city_3 = select(data,city_3_boundaries)\n",
      "city_4 = select(data,city_4_boundaries)\n",
      "city_5 = select(data,city_5_boundaries)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "See an example of some of the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "city_2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>summary</th>\n",
        "      <th>description</th>\n",
        "      <th>num_votes</th>\n",
        "      <th>num_comments</th>\n",
        "      <th>num_views</th>\n",
        "      <th>source</th>\n",
        "      <th>created_time</th>\n",
        "      <th>tag_type</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td> 317026</td>\n",
        "      <td> 37.843478</td>\n",
        "      <td>-122.245946</td>\n",
        "      <td>               Pothole</td>\n",
        "      <td>                               Pothole in street\\n</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 177</td>\n",
        "      <td> iphone</td>\n",
        "      <td> 2012-01-02 18:06:44</td>\n",
        "      <td>       pothole</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td> 379955</td>\n",
        "      <td> 37.839588</td>\n",
        "      <td>-122.251488</td>\n",
        "      <td> Parking meter station</td>\n",
        "      <td> Appears to have been hit by car. Out of operat...</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 164</td>\n",
        "      <td> iphone</td>\n",
        "      <td> 2012-01-02 18:55:09</td>\n",
        "      <td> parking_meter</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td>  16578</td>\n",
        "      <td> 37.793552</td>\n",
        "      <td>-122.213066</td>\n",
        "      <td>       Illegal Dumping</td>\n",
        "      <td> Please invest in a camera to catch and stop th...</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 166</td>\n",
        "      <td> iphone</td>\n",
        "      <td> 2012-01-02 20:29:54</td>\n",
        "      <td>         trash</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42</th>\n",
        "      <td> 376412</td>\n",
        "      <td> 37.814213</td>\n",
        "      <td>-122.268333</td>\n",
        "      <td>       Illegal Dumping</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td>  89</td>\n",
        "      <td> iphone</td>\n",
        "      <td> 2012-01-03 06:24:40</td>\n",
        "      <td>         trash</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>86</th>\n",
        "      <td> 201228</td>\n",
        "      <td> 37.808846</td>\n",
        "      <td>-122.255119</td>\n",
        "      <td>              Sidewalk</td>\n",
        "      <td> So the overflowing trash can was emptied - but...</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td>  59</td>\n",
        "      <td> iphone</td>\n",
        "      <td> 2012-01-03 15:44:30</td>\n",
        "      <td>         trash</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "        id   latitude   longitude                summary  \\\n",
        "31  317026  37.843478 -122.245946                Pothole   \n",
        "33  379955  37.839588 -122.251488  Parking meter station   \n",
        "36   16578  37.793552 -122.213066        Illegal Dumping   \n",
        "42  376412  37.814213 -122.268333        Illegal Dumping   \n",
        "86  201228  37.808846 -122.255119               Sidewalk   \n",
        "\n",
        "                                          description  num_votes  \\\n",
        "31                                Pothole in street\\n          4   \n",
        "33  Appears to have been hit by car. Out of operat...          4   \n",
        "36  Please invest in a camera to catch and stop th...          2   \n",
        "42                                                NaN          4   \n",
        "86  So the overflowing trash can was emptied - but...          2   \n",
        "\n",
        "    num_comments  num_views  source         created_time       tag_type  \n",
        "31             1        177  iphone  2012-01-02 18:06:44        pothole  \n",
        "33             1        164  iphone  2012-01-02 18:55:09  parking_meter  \n",
        "36             1        166  iphone  2012-01-02 20:29:54          trash  \n",
        "42             1         89  iphone  2012-01-03 06:24:40          trash  \n",
        "86             1         59  iphone  2012-01-03 15:44:30          trash  "
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Sanity check"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert (data.id.size == city_1.id.size + city_2.id.size + city_3.id.size + city_4.id.size + city_5.id.size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "let's put all those cities in an array:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#messy\n",
      "city_1.city_name = 'city_1'\n",
      "city_2.city_name = 'city_2'\n",
      "city_3.city_name = 'city_3'\n",
      "city_4.city_name = 'city_4'\n",
      "city_5.city_name = 'city_5'\n",
      "\n",
      "cities_data = [city_1,city_2,city_3,city_4,city_5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "What are the sources for each city?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "A 'source' is where it came from - e.g iphone or something else"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for city in cities_data:\n",
      "    sources = np.unique(city.source.values)\n",
      "    city.unique_sources = sources\n",
      "    print city.unique_sources"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Map Widget' 'Mobile Site' 'New Map Widget' 'android' 'city_initiated'\n",
        " 'iphone' 'unknown' 'web']\n",
        "['Map Widget' 'Mobile Site' 'New Map Widget' 'android' 'iphone'\n",
        " 'remote_api_created' 'unknown' 'web']\n",
        "['Map Widget' 'Mobile Site' 'New Map Widget' 'android' 'city_initiated'\n",
        " 'iphone' 'unknown' 'web']\n",
        "['Map Widget' 'Mobile Site' 'New Map Widget' 'android' 'city_initiated'\n",
        " 'iphone' 'unknown' 'web']\n",
        "['Map Widget' 'Mobile Site' 'New Map Widget' 'android' 'iphone'\n",
        " 'remote_api_created' 'unknown' 'web']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Build all the niches"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "A niche is a subset of data. Niches do not share members with any other niches"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def source_niches_from_city(city):\n",
      "    \"\"\"\n",
      "    Given a city or niche, breaks it  further down\n",
      "    into niches by the source\n",
      "    \"\"\"\n",
      "    niches = []\n",
      "    sources = city.unique_sources\n",
      "    for source in sources:\n",
      "        frame = city[city.source == source]\n",
      "        frame.source_str = source\n",
      "        frame.city_name = city.city_name\n",
      "        niches.append(frame)\n",
      "    return niches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Dataset is now divided by city and source put all those subsets (niches) into an array:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "city_and_source_niches = []\n",
      "for city in cities_data:\n",
      "    niches = source_niches_from_city(city)\n",
      "    city_and_source_niches += niches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Now make smaller niches than the previous, using tags"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Assign a 'unique tags' attribute to each source + city niche, this is a list of unique tags the niche contains. This is very messy, each dict should have an attributes hashtable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for niche in city_and_source_niches:\n",
      "    tags = np.unique(niche.tag_type.values)\n",
      "    niche.unique_tags = tags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Now we make even smaller niches, dividing a niche down into sub-niches which take tag into account"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tag_niches_from_niche(super_niche):\n",
      "    \"\"\"\n",
      "    Given a city or, breaks it down\n",
      "    into niches by the source\n",
      "    \"\"\"\n",
      "    niches = []\n",
      "    tags = super_niche.unique_tags\n",
      "    for tag in tags:\n",
      "        frame = super_niche[super_niche.tag_type == tag]\n",
      "        if frame.id.size == 0:\n",
      "            print 'NO ' + tag + ' but it is in its unique tags:'\n",
      "            #print city.unique_tags\n",
      "        frame.tag_str = tag\n",
      "        frame.source_str = super_niche.source_str #very bad design because it is assumed this attribute exists\n",
      "        frame.city_name = super_niche.city_name #very bad design because it is assumed this attribute exists\n",
      "        niches.append(frame)\n",
      "    #sanity check:\n",
      "    assert(super_niche.id.size == sum([niche.id.size for niche in niches]))\n",
      "    return niches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "city_source_and_tag_niches = []\n",
      "for niche in city_and_source_niches:\n",
      "    niches = tag_niches_from_niche(niche)\n",
      "    city_source_and_tag_niches += niches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Now going to a very high degree of granularity:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(city_source_and_tag_niches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "814\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Now we calculate the means for each niche"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_mean(city):\n",
      "    \"\"\"\n",
      "    Calculates the scaled (log(x + 1)) mean for training data or subset\\n\",\n",
      "    of it\n",
      "    \"\"\"\n",
      "    num_views = city.num_views\n",
      "    num_votes = city.num_votes\n",
      "    num_comments = city.num_comments\n",
      "    log_num_views = map(math.log,num_views + 1)\n",
      "    log_num_votes = map(math.log,num_votes + 1)\n",
      "    log_num_comments = map(math.log,num_comments + 1)\n",
      "\n",
      "    mean_log_num_views = np.mean(log_num_views)\n",
      "    mean_log_num_votes = np.mean(log_num_votes)\n",
      "    mean_log_num_comments = np.mean(log_num_comments)\n",
      "    return mean_log_num_views, mean_log_num_votes, mean_log_num_comments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for niche in city_source_and_tag_niches:\n",
      "      niche.means =  np.exp(log_mean(niche)) - 1\n",
      "for niche in city_and_source_niches:\n",
      "      niche.means =  np.exp(log_mean(niche)) - 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Populate a dict with all the means (for each niche,including the superniches)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "means_dict = {}\n",
      "for niche in city_source_and_tag_niches:\n",
      "    key = niche.city_name + niche.source_str + niche.tag_str\n",
      "    means_dict[key] = niche.means\n",
      "#also populate the means_dict with superniches:\n",
      "for niche in city_and_source_niches:\n",
      "    key = niche.city_name + niche.source_str\n",
      "    means_dict[key] = niche.means\n",
      "print len(means_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "854\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load the test data and separate it out into niches, assigning a projected mean to each one (this could be much better..)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data = pandas.read_csv('/home/mike/dev/311/data/test_reformatted_2.csv')\n",
      "\n",
      "\n",
      "num_data_points = test_data.id.size\n",
      "\n",
      "print 'number of data points:'\n",
      "print num_data_points\n",
      "\n",
      "test_city_1 = select(test_data,city_1_boundaries)\n",
      "test_city_2 = select(test_data,city_2_boundaries)\n",
      "test_city_3 = select(test_data,city_3_boundaries)\n",
      "test_city_4 = select(test_data,city_4_boundaries)\n",
      "test_city_5 = select(test_data,city_5_boundaries)\n",
      "\n",
      "test_city_1.city_name = 'city_1'\n",
      "test_city_2.city_name = 'city_2'\n",
      "test_city_3.city_name = 'city_3'\n",
      "test_city_4.city_name = 'city_4'\n",
      "test_city_5.city_name = 'city_5'\n",
      "\n",
      "test_cities_data = [test_city_1,test_city_2,test_city_3,test_city_4,test_city_5]\n",
      "\n",
      "#sanity check:\n",
      "assert (test_data.id.size == test_city_1.id.size + test_city_2.id.size + test_city_3.id.size + test_city_4.id.size + test_city_5.id.size)\n",
      "\n",
      "#again, work out the source niches:\n",
      "for city in test_cities_data:\n",
      "    sources = np.unique(city.source.values)\n",
      "    city.unique_sources = sources\n",
      "\n",
      "all_test_niches = []\n",
      "for city in test_cities_data:\n",
      "    niches = source_niches_from_city(city)\n",
      "    all_test_niches += niches\n",
      "\n",
      "assert (test_data.id.size == sum([niche.id.size for niche in all_test_niches]))\n",
      "    \n",
      "for niche in all_test_niches:\n",
      "    #print tags\n",
      "    tags = np.unique(niche.tag_type.values)\n",
      "    niche.unique_tags = tags\n",
      "\n",
      "smaller_test_niches = []\n",
      "for niche in all_test_niches:\n",
      "    niches = tag_niches_from_niche(niche)\n",
      "    smaller_test_niches += niches\n",
      "\n",
      "#sanity check:\n",
      "assert (test_data.id.size == sum([niche.id.size for niche in smaller_test_niches]))    \n",
      "\n",
      "i = 0\n",
      "for niche in smaller_test_niches:\n",
      "    key = niche.city_name + niche.source_str + niche.tag_str\n",
      "    try:\n",
      "        mean = means_dict[key]\n",
      "    except:\n",
      "        i += 1\n",
      "        #here we have a problem,certain niches in the test data\n",
      "        #do not occur in the training, we need to resolve this\n",
      "        #by using the superniche, which itself should be added to the dict.        \n",
      "        key = niche.city_name + niche.source_str\n",
      "        mean = means_dict[key]\n",
      "    niche.projected_means = mean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of data points:\n",
        "149575\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Let's populate the arrays:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_views = []\n",
      "num_votes = []\n",
      "num_comments = []\n",
      "ids = ['id']\n",
      "\n",
      "for niche in smaller_test_niches:\n",
      "      for id in niche.id:\n",
      "          ids.append(id)\n",
      "          #I am adding 0.001 to get rid of an extremely insidious truncation error,\n",
      "          #this step is CRITICAL\n",
      "          num_views.append(niche.projected_means[0]+0.001)\n",
      "          num_votes.append(niche.projected_means[1]+0.001)\n",
      "          num_comments.append(niche.projected_means[2]+0.001)\n",
      "\n",
      "print len(ids)\n",
      "print len(num_votes)\n",
      "print len(num_comments)\n",
      "print len(num_views)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "149576\n",
        "149575\n",
        "149575\n",
        "149575\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Now apply means correction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction = (np.array(num_comments),np.array(num_views),np.array(num_votes))\n",
      "log_mean = learn.set_log_mean\n",
      "scaled_prediction = log_mean(prediction) # this fn should accept one array and one tog and one array."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fudge factors: {comments:0.764984071255}, {views: 0.391607105732}, {votes: 1.01202839613}.\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prepared_comments = np.concatenate([['num_comments'], scaled_prediction[0]])\n",
      "prepared_views = np.concatenate([['num_views'], scaled_prediction[1]])\n",
      "prepared_votes = np.concatenate([['num_votes'], scaled_prediction[2]])\n",
      "\n",
      "csv_list = np.array([ids,prepared_views,prepared_votes,prepared_comments])\n",
      "csv_list = csv_list.T\n",
      "print shape(csv_list)\n",
      "with open(\"submission_trial.csv\", \"wb\") as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(csv_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(149576, 4)\n"
       ]
      }
     ],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}